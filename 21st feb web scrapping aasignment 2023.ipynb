{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c580fa",
   "metadata": {},
   "source": [
    "# 21st Feb Assignment 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d92f2",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd62d7e",
   "metadata": {},
   "source": [
    "* Web scraping is the process of automatically collecting data from websites, usually in an unstructured HTML format. It involves using software or tools to extract information from web pages, which can then be analyzed or used for various purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03535d4",
   "metadata": {},
   "source": [
    "* Web scraping is used for a variety of reasons, such as market research, competitor analysis, data analysis, and data mining. It allows businesses and individuals to gather information quickly and efficiently, without the need for manual data entry. Web scraping is also used to monitor changes in websites, such as price changes or stock availability, and to extract data for research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e1e401",
   "metadata": {},
   "source": [
    "* Three areas where web scraping is commonly used to get data include:\n",
    "\n",
    "E-commerce: Web scraping can be used to extract data about products and prices from various e-commerce websites like Amazon, eBay, and Google Shopping. This data can then be used for price comparison, market research, and competitor analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cf8cc",
   "metadata": {},
   "source": [
    "* Social media: Web scraping can be used to extract data from social media platforms like Twitter, Facebook, and Instagram. This data can include user profiles, posts, and comments, which can be analyzed to gain insights into user behavior and preferences.\n",
    "\n",
    "    \n",
    "* Research: Web scraping is also used in research, particularly in fields like journalism, data journalism, and data science. It can be used to extract data from various sources, such as news websites and government databases, for analysis and research purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a40dd",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133fa9d6",
   "metadata": {},
   "source": [
    "There are various methods used for web scraping that include manual scraping, automated scraping, and outsourced web scraping.\n",
    "\n",
    "Manual scraping involves copying and pasting data from websites into spreadsheets or files. This method is useful for scraping small amounts of data and is suitable for users who are not familiar with programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45954a6a",
   "metadata": {},
   "source": [
    "* Automated scraping involves using software to extract data from websites. This method is useful for scraping large amounts of data, and it can be customized to scrape specific data points. Some of the popular techniques used in automated scraping include HTML parsing, DOM parsing, vertical aggregation, XPath, and Google Sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3144118",
   "metadata": {},
   "source": [
    "* Outsourced web scraping involves hiring a third-party service provider to scrape data from websites. This method is useful for businesses that require large-scale data extraction but lack the expertise or resources to do it themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0d0f8",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f22a5ab",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that is commonly used for web scraping tasks. Web scraping is the process of extracting data from websites, and Beautiful Soup helps in this process by providing simple methods for navigating, searching, and modifying a parse tree in HTML and XML files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379fca9",
   "metadata": {},
   "source": [
    "* It is particularly useful for extracting data from websites that do not have an API, as it allows users to programmatically access and extract data from these websites. Beautiful Soup is also useful for cleaning and organizing data, as it can remove unnecessary HTML markup and transform the data into a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb4d57",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81355d73",
   "metadata": {},
   "source": [
    "In a web scraping project, Flask can be used to create a web application that scrapes data from websites and displays the results in a user-friendly way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae64e0",
   "metadata": {},
   "source": [
    "* Flask is commonly used in web scraping projects because it is a lightweight and beginner-friendly web framework that is written in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d72194",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e04c1a",
   "metadata": {},
   "source": [
    " * CodePipeline and AWS Elastic Beanstalk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54d88a",
   "metadata": {},
   "source": [
    "* Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deploymentâ€”from capacity provisioning, load balancing, and auto scaling to application health monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523d99e",
   "metadata": {},
   "source": [
    "* AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release your software changes continuously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8199d9",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0440b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
